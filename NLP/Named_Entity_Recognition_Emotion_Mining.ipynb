{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xle6UYfIaYs"
   },
   "source": [
    "#### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QoFa8MxWQqQm"
   },
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzduaJKZSjBt"
   },
   "outputs": [],
   "source": [
    "###Execute below command through anaconda command prompt\n",
    "!python -m spacy download en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KR54eo-MIaYs"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import string # special operations on strings\n",
    "import spacy # language models\n",
    "\n",
    "from matplotlib.pyplot import imread\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9UQFM-kIaYs"
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "book=pd.read_csv(\"https://raw.githubusercontent.com/slmsshk/DataSet/main/apple.txt\",error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wcld8yJKIaYt"
   },
   "outputs": [],
   "source": [
    "book = [x.strip() for x in book.x] # remove both the leading and the trailing characters\n",
    "book = [x for x in book if x] # removes empty strings, because they are considered in Python as False\n",
    "book[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XheJZ3rkM7Up"
   },
   "outputs": [],
   "source": [
    "book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1kyy_QSZIaYu"
   },
   "outputs": [],
   "source": [
    "##Part Of Speech Tagging\n",
    "#nlp = spacy.load('en')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "one_block = book[2]\n",
    "doc_block = nlp(one_block)\n",
    "spacy.displacy.render(doc_block, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEarLyAMIaYu"
   },
   "outputs": [],
   "source": [
    "one_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nOzOl8b3IaYu"
   },
   "outputs": [],
   "source": [
    "for token in doc_block[0:20]:\n",
    "    print(token, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rntdt4F_IaYu"
   },
   "outputs": [],
   "source": [
    "#Filtering for nouns and verbs only\n",
    "nouns_verbs = [token.text for token in doc_block if token.pos_ in ('NOUN', 'VERB')]\n",
    "print(nouns_verbs[5:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0n9LITfIaYu"
   },
   "outputs": [],
   "source": [
    "#Counting tokens again\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "\n",
    "X = cv.fit_transform(nouns_verbs)\n",
    "sum_words = X.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "wf_df = pd.DataFrame(words_freq)\n",
    "wf_df.columns = ['word', 'count']\n",
    "\n",
    "wf_df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KTNrkuimIaYu"
   },
   "outputs": [],
   "source": [
    "##Visualizing results\n",
    "#Barchart for top 10 nouns + verbs\n",
    "wf_df[0:10].plot.bar(x='word', figsize=(12,8), title='Top verbs and nouns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdOogyK5IaYv"
   },
   "source": [
    "### Emotion Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzmJ2qtXIaYv"
   },
   "outputs": [],
   "source": [
    "#Sentiment analysis\n",
    "afinn = pd.read_csv('https://raw.githubusercontent.com/slmsshk/DataSet/main/Afinn.csv', sep=',', encoding='latin-1')\n",
    "afinn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d27chQomIaYv"
   },
   "outputs": [],
   "source": [
    "afinn[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6izfLk6UIaYv"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import string # special operations on strings\n",
    "import spacy # language models\n",
    "\n",
    "from matplotlib.pyplot import imread\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas\n",
    "book=pd.read_csv(\"https://raw.githubusercontent.com/slmsshk/DataSet/main/apple.txt\",error_bad_lines=False)\n",
    "book = [x.strip() for x in book.x] # remove both the leading and the trailing characters\n",
    "book = [x for x in book if x] # removes empty strings, because they are considered in Python as False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vVNytlqGJx8N"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwYOXYMiIaYv"
   },
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "sentences = tokenize.sent_tokenize(\" \".join(book))\n",
    "sentences[5:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AXwOf2nrIaYv"
   },
   "outputs": [],
   "source": [
    "sent_df = pd.DataFrame(sentences, columns=['sentence'])\n",
    "sent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCOX-qjTIaYv"
   },
   "outputs": [],
   "source": [
    "affinity_scores = afinn.set_index('word')['value'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TSf-SSPpw4V-"
   },
   "outputs": [],
   "source": [
    "affinity_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1IZL55WIaYv"
   },
   "outputs": [],
   "source": [
    "#Custom function :score each word in a sentence in lemmatised form, \n",
    "#but calculate the score for the whole original sentence.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "sentiment_lexicon = affinity_scores\n",
    "\n",
    "def calculate_sentiment(text: str = None):\n",
    "    sent_score = 0\n",
    "    if text:\n",
    "        sentence = nlp(text)\n",
    "        print(sentence)\n",
    "        for word in sentence:\n",
    "            sent_score += sentiment_lexicon.get(word.lemma_, 0)\n",
    "    return sent_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHIcKrl3IaYv"
   },
   "outputs": [],
   "source": [
    "# test that it works\n",
    "calculate_sentiment(text = 'Amazed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VYqKJG6ZyrwF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JgMG93cLIaYv"
   },
   "outputs": [],
   "source": [
    "sent_df['sentiment_value'] = sent_df['sentence'].apply(calculate_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "beMlrPKUzTaL"
   },
   "outputs": [],
   "source": [
    "sent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ViXBNIk_IaYv"
   },
   "outputs": [],
   "source": [
    "# how many words are in the sentence?\n",
    "sent_df['word_count'] = sent_df['sentence'].str.split().apply(len)\n",
    "sent_df['word_count'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ju6kybVAIaYv"
   },
   "outputs": [],
   "source": [
    "sent_df.sort_values(by='sentiment_value').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hAGFBNlBIaYv"
   },
   "outputs": [],
   "source": [
    "# Sentiment score of the whole review\n",
    "sent_df['sentiment_value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDg4T2EnIaYw"
   },
   "outputs": [],
   "source": [
    "# Sentiment score of the whole review\n",
    "sent_df[sent_df['sentiment_value']<=0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVDlmVhUIaYw"
   },
   "outputs": [],
   "source": [
    "sent_df[sent_df['sentiment_value']<-5].head()['sentence'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mc8yfN7IaYw"
   },
   "outputs": [],
   "source": [
    "sent_df['index']=range(0,len(sent_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFsUR-i3IaYw"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(style='white') \n",
    "\n",
    "sns.displot(data=sent_df,x='sentiment_value',kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCuDSnvqIaYw"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.lineplot(y='sentiment_value',x='index',data=sent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WHePZ2ieIaYw"
   },
   "outputs": [],
   "source": [
    "sent_df.plot.scatter(x='word_count', y='sentiment_value', figsize=(8,8), title='Sentence sentiment value to sentence word count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZ1KV4vZ5_hs"
   },
   "source": [
    "<h1><center> ꧁༺ȶɦǟռӄ ʏօʊ༻꧂"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
